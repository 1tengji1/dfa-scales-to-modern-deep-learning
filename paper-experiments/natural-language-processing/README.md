# Scaling-up DFA -- Natural Language Processing

## Organization

`train_lm.py` contains all the training logic and provides results for Table 5. `attention.py`, `radam.py`, `transformer.py`, and `utils.py` all contains code related to our implementation of the Transformer.  

## Reproducibility 

To reproduce our results: 
```bash
./run_experiments.sh
``` 
